<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ImOV3D</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ImOV3D: Learning <u>O</u>pen-<u>V</u>ocabulary Point Clouds <u>3D</u> Object Detection from Only 2D <u>Im</u>ages
</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://yangtiming.github.io" target="_blank">Timing Yang</a><sup>1,2*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Yuanliang Ju</a><sup>1,2*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Li Yi</a><sup>2,3,1 &#8224;</sup>
                  </span>
                  </div>

                  <div class="is-size-6 publication-authors">
                    <span class="author-block"><sup>1</sup> Shanghai Qi Zhi Institute, <sup>2</sup> IIIS, Tsinghua University, <sup>3</sup> Shanghai AI Lab
<br><b>NeurIPS 2024</b></span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution</small></span>
                    <span class="eql-cntrb"><small><br><sup>&#8224;</sup>Corresponding Author</small></span>
                    
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">

                <!-- ArXiv abstract Link without background and bold icon/text -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  style="text-decoration: none; border: none; background: none; font-weight: bold; color: black;">
                    <span class="icon" style="color: black;">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span style="font-weight: bold; color: black;">arXiv</span>
                  </a>
                </span>



              <!-- Github link without background and bold icon/text -->
              <span class="link-block">
                <a href="https://github.com/YOUR REPO HERE" target="_blank"
                style="text-decoration: none; border: none; background: none; font-weight: bold; color: black;">
                  <span class="icon" style="color: black;">
                    <i class="fab fa-github"></i>
                  </span>
                  <span style="font-weight: bold; color: black;">Code</span>
                </a>
              </span>

                                      

            <!-- Video link without background and bold icon/text -->
            <span class="link-block">
              <a href="static/videos/video_link.mp4" target="_blank"
              style="text-decoration: none; border: none; background: none; font-weight: bold; color: black;">
                <span class="icon" style="color: black;">
                  <i class="fas fa-video"></i>
                </span>
                <span style="font-weight: bold; color: black;">Video</span>
              </a>
            </span>



    



                      
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Open-vocabulary 3D object detection (OV-3Det) aims to generalize beyond the limited number of base categories labeled during the training phase. The biggest bottleneck is the scarcity of annotated 3D data, whereas 2D image datasets are abundant and richly annotated. Consequently, it is intuitive to leverage the wealth of annotations in 2D images to alleviate the inherent data scarcity in OV-3Det. In this paper, we push the task setup to its limits by exploring the potential of using solely 2D images to learn OV-3Det. The major challenges for this setup is the modality gap between training image and testing point cloud, which prevents effective integration of 2D knowledge into OV-3Det. To address this challenge, we propose a novel framework ImOV3D to leverage pseudo multimodal representation containing both images and point clouds (PC) to close the modality gap. The key of ImOV3D lies in flexible modality conversion where 2D images can be lifted into 3D using monocular depth estimation and can also be derived from 3D scenes through rendering. This allows unifying both training images and testing point cloud into a common image-PC representation, encompassing a wealth of 2D semantic information and also incorporating the depth and structural characteristics of 3D spatial data. We carefully conduct such conversion to minimize the domain gap between training and test cases. Extensive experiments on two benchmark datasets, SUNRGBD and ScanNet, show that ImOV3D significantly outperforms existing methods, even in the absence of ground truth 3D training data. With the inclusion of a minimal amount of real 3D data for fine-tuning, the performance also significantly surpasses previous state-of-the-art.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <h2 class="title is-3 has-text-centered">Overview of ImOV3D</h2>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/t1.png" alt="Overview image" style="width: 80%; margin: 0 auto; display: block;"/>
          <div style="max-width: 70%; margin: 0 auto;">
            <h2 class="subtitle has-text-centered">
              <b>Left</b>: Traditional methods require paired RGB-D data for training and use single-modality
              point clouds input during inference. <b>Right</b>: ImOV3D involves using a vast amount of 2D images
              to generate pseudo point clouds during the training phase, which are then rendered back into
              images. In the inference phase, with only point clouds input, we still construct a pseudo multimodal
              representation to enhance detection performance.
            </h2>
          </div>
        </div>

        <div class="item">
          <!-- Your image here -->
          <img src="static/images/overview_ImOV3D.png" alt="Overview image" style="width: 70%; margin: 0 auto; display: block;"/>
          <div style="max-width: 70%; margin: 0 auto;">
            <h2 class="subtitle has-text-centered">
              Our model takes 2D images as input and puts them into the Pseudo
              3D Annotation Generator to produce pseudo annotations. These 2D images are also fed into the
              Point Cloud Lifting Module to generate pseudo point clouds. Subsequently, using the Point Cloud
              Renderer, these pseudo point clouds are rendered into pseudo images, which then get processed by a
              2D open vocabulary detector to detect 2D proposals and transfer the 2D semantic information to 3D
              space. Armed with pseudo point clouds, annotations, and pseudo images data, we proceed to train a
              multimodal 3D detector.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->
  
<!-- Overview image section -->  
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">3D Data Revision Module</h2>
      <div class="overview-image">
        <!-- Adjust the image size by setting width -->
        <img src="static/images/77.png" alt="Overview image" style="width: 70%; margin: 0 auto; display: block;"/>
        <div style="max-width: 80%; margin: 0 auto;">
          <h2 class="subtitle has-text-centered">
            <b>(a)</b> The rotation correction module involves processing an RGB image through a Normal Estimator to generate a normal map. This map then helps extract a horizontal surface mask for identifying horizontal point clouds, from which normal vectors are obtained. These vectors are aligned with the Z-axis to compute the rotation matrix. <b>(b)</b> In the 3D box filtering module, prompts related to object dimensions are first provided to GPT-4 to determine the mean size for each category. This mean size is then used to filter out boxes that do not meet the threshold criteria.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End overview image section -->




<!-- Image carousel -->
<section class="hero is-small">
  <h2 class="title is-3 has-text-centered">Visualization of Overview</h2>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <!-- Your image here -->
          <img src="static/images/demo_0000.png" alt="Overview image" style="width: 80%; margin: 0 auto; display: block;"/>
          <div style="max-width: 70%; margin: 0 auto;">
            <h2 class="subtitle has-text-centered">
              Scene_0000_01 Visualization
            </h2>
          </div>
        </div>

        <div class="item">
          <!-- Your image here -->
          <img src="static/images/demo_0012.png" alt="Overview image" style="width: 70%; margin: 0 auto; display: block;"/>
          <div style="max-width: 70%; margin: 0 auto;">
            <h2 class="subtitle has-text-centered">
              Scene_0012_01 Visualization
            </h2>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->



  
<!-- Image carousel -->
<section class="section hero is-light">
  <h2 class="title is-3 has-text-centered">xxxx</h2>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->



<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Table Demo</title>
    <style>
        table {
            width: 50%;
            margin: 20px auto;
            border-collapse: collapse;
        }
        th, td {
            border: 1px solid #dddddd;
            text-align: center;
            padding: 8px;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>
    <h2 class="title has-text-centered">Table Demo</h2>
    <table>
        <thead>
            <tr>
                <th>Category</th>
                <th>Description</th>
                <th>Value</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Rotation Correction</td>
                <td>Aligns normal vectors with Z-axis</td>
                <td>\( R \)</td>
            </tr>
            <tr>
                <td>Point Cloud Filtering</td>
                <td>Filters boxes based on GPT-4 derived size</td>
                <td>Mean size</td>
            </tr>
            <tr>
                <td>Depth Estimation</td>
                <td>Generates pseudo point clouds</td>
                <td>Depth map</td>
            </tr>
        </tbody>
    </table>
</body>
</html>



<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
